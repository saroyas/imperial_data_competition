{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "np.set_printoptions(suppress=True)\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "from tensorflow.keras import regularizers, layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_un = pd.read_csv('train_data.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _preprocessor(self, X_raw, training = False):\n",
    "        \"\"\"\n",
    "\n",
    "        This function prepares the features of the data for training,\n",
    "        evaluation, and prediction.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_raw : Pandas dataframe\n",
    "            This is the raw data features excluding claims information \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X: Pandas DataFrame\n",
    "            A clean data set that is used for training and prediction.\n",
    "        \"\"\"\n",
    "        # =============================================================\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        columns_x = ['pol_bonus', 'pol_coverage', 'pol_duration',\n",
    "                     'pol_sit_duration', 'pol_pay_freq', 'pol_payd', 'pol_usage',\n",
    "                     'drv_drv2', 'drv_age1', 'drv_age2', 'drv_sex1',\n",
    "                     'drv_sex2', 'drv_age_lic1', 'drv_age_lic2', 'vh_age', 'vh_cyl',\n",
    "                     'vh_din', 'vh_fuel', 'vh_make', 'vh_sale_begin',\n",
    "                     'vh_sale_end', 'vh_speed', 'vh_type', 'vh_value', 'vh_weight',\n",
    "                     'town_mean_altitude', 'town_surface_area', 'population', 'city_district_code',\n",
    "                     ]\n",
    "\n",
    "        x_data_un = X_raw[columns_x]\n",
    "\n",
    "        cat_to_int_dict = {'pol_coverage': {'Mini': 0, 'Median1': 1, 'Median2': 2, 'Maxi': 3},\n",
    "                           'pol_pay_freq': {'Monthly': 0, 'Quarterly': 1, 'Biannual': 2, 'Yearly': 3},\n",
    "                           'pol_payd': {'No': 0, 'Yes': 1},\n",
    "                           'pol_usage': {'Retired': 0, 'WorkPrivate': 1, 'Professional': 2, 'AllTrips': 3},\n",
    "                           'drv_drv2': {'No': 0, 'Yes': 1},\n",
    "                           'drv_sex1': {'F': 0, 'M': 1},\n",
    "                           'drv_sex2': {'F': -1, 'M': 1, None: 0},\n",
    "                           'vh_type': {'Tourism': 0, 'Commercial': 1, }\n",
    "                           }\n",
    "\n",
    "        def car_make_categories(car_make):\n",
    "            if car_make in ['RENAULT', 'PEUGEOT', 'CITROEN', 'VOLKSWAGEN', 'FORD', 'MERCEDES BENZ']:\n",
    "                return car_make\n",
    "            else:\n",
    "                return 'OTHER'\n",
    "\n",
    "        def missing_geo_data(x):\n",
    "            if x:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        def zero_vh_weight(weight, avg_weight):\n",
    "            if weight < 100:\n",
    "                return avg_weight\n",
    "            else:\n",
    "                return weight\n",
    "\n",
    "        x_data_f = x_data_un.replace(cat_to_int_dict, inplace=False)\n",
    "\n",
    "        x_data_f.vh_make = x_data_f['vh_make'].apply(lambda x: car_make_categories(x))\n",
    "\n",
    "        ##MAKE INDEP\n",
    "        avg_vh_weight = x_data_f['vh_weight'].mean()\n",
    "        x_data_f.vh_weight = x_data_f['vh_weight'].apply(lambda x: zero_vh_weight(x, avg_vh_weight))\n",
    "\n",
    "        vh_make_cols = pd.get_dummies(x_data_f.vh_make)\n",
    "        vh_fuel_cols = pd.get_dummies(x_data_f.vh_fuel)\n",
    "        city_dist_cols = pd.get_dummies(x_data_f.city_district_code)\n",
    "        x_data_f = x_data_f.drop(['vh_fuel', 'vh_make', 'city_district_code'], axis=1)\n",
    "\n",
    "        x_data_f['geoNA'] = (x_data_un['population'].isnull()).apply(lambda x: missing_geo_data(x))\n",
    "\n",
    "        x_data_f = pd.concat([x_data_f, vh_make_cols, vh_fuel_cols, city_dist_cols], axis=1, sort=False)\n",
    "\n",
    "        #NEED TO CHANGE MEANS SO THAT ITS INDEPENDENT\n",
    "        means = x_data_f.mean()\n",
    "        x_data_f = x_data_f.fillna(means)\n",
    "\n",
    "        #SIMILIAARLY I NEED TO CHANGE THIS SCALER SO THAT ITS INDEPENDENT\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        if training == True:\n",
    "            self.scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "        X = pd.DataFrame(scaler.fit_transform(x_data_f), columns=x_data_f.columns, index=x_data_f.index)\n",
    "\n",
    "        return X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
